{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f2d3481-26c9-4c21-b574-69102fc8338b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File: 250504-final_code_with_web_data.ipynb\n",
    "# Created with assistance of ChatGPT (OpenAI) â€“ reviewed on 2025-05-04\n",
    "# Author: Maria Heinrich\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56139d64-5d61-4ba8-8ee2-d13ade2c8245",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d442802-5c7a-467e-8bf7-52951c120cc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf68d49b-397e-4d2f-8dd8-73945a0dd0db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5c7c5bb-42e5-4a8a-9821-ec37bd88934c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Exchange rate table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc90400e-194c-4adf-8fd1-2e3a9b14c491",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fetch data from the URL\n",
    "url = \"https://www.oenb.at/oearb/zinssatzwechselkurse/download-zeitreihe?start=2023-01-01&end=2023-06-30&codes=AUD,BGN,BRL,CAD,CHF,CNY,CZK,DKK,GBP,HKD,HUF,IDR,ILS,INR,ISK&format=CSV\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Read the CSV data\n",
    "csv_data = StringIO(response.text)\n",
    "df = pd.read_csv(csv_data, delimiter=';')\n",
    "\n",
    "# Parse the date string from the first row\n",
    "date_str = df.at[0, 'Datum']\n",
    "date_format = '%Y-%m-%d'  # Changed date format\n",
    "datum = datetime.strptime(date_str, date_format)\n",
    "\n",
    "# Subtract one day from the date\n",
    "new_date = datum - timedelta(days=1)\n",
    "\n",
    "# Convert the new date back to the string format\n",
    "new_date_str = new_date.strftime(date_format)\n",
    "\n",
    "# Replace the date in the first row with the new date\n",
    "df.at[0, 'Datum'] = new_date_str\n",
    "\n",
    "# Melt the DataFrame to create the desired table structure\n",
    "melted_df = df.melt(id_vars=[\"Datum\"], var_name=\"CurrencyCode\", value_name=\"ExchangeRate\")\n",
    "\n",
    "melted_df.rename(columns={\"Datum\": \"Date\"}, inplace=True)\n",
    "\n",
    "melted_df['Date'] = pd.to_datetime(melted_df['Date'], format='%Y-%m-%d')\n",
    "\n",
    "# DataFrame updated with the melted DataFrame\n",
    "df = melted_df\n",
    "\n",
    "# Convert 'date' column to datetime if it's not already\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Set 'date' column as the index temporarily to fill the missing values for each currency\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Group by 'CurrencyCode' and fill missing values for each group separately\n",
    "df['ExchangeRate'] = df.groupby('CurrencyCode')['ExchangeRate'].ffill()\n",
    "\n",
    "# Reset index to move 'date' back to a column\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# If needed, convert 'date' back to string format\n",
    "df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = datetime(2023, 1, 1)\n",
    "end_date = datetime(2023, 6, 30)  # Adjust the end date as needed\n",
    "\n",
    "# Generate a list of dates in the range\n",
    "date_list = [start_date + timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
    "\n",
    "# Convert date_list to a DataFrame\n",
    "date_df = pd.DataFrame({'Date': date_list})\n",
    "\n",
    "# Initialize an empty DataFrame to store results\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each currency code\n",
    "for currency_code in df['CurrencyCode'].unique():\n",
    "    # Filter the DataFrame for the current currency code\n",
    "    currency_df = df[df['CurrencyCode'] == currency_code]\n",
    "    \n",
    "    # Group by 'date' and aggregate the data\n",
    "    grouped_df = currency_df.groupby('Date').agg({'ExchangeRate': 'first'}).reset_index()\n",
    "    \n",
    "    # Convert 'date' column to datetime\n",
    "    grouped_df['Date'] = pd.to_datetime(grouped_df['Date'])\n",
    "    \n",
    "    # Merge date_df with the aggregated DataFrame on 'date' to match the dates\n",
    "    merged_df = pd.merge(date_df, grouped_df, on='Date', how='left')\n",
    "    \n",
    "    # Forward fill missing values for the current currency\n",
    "    merged_df['ExchangeRate'].fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    # Add 'CurrencyCode' column\n",
    "    merged_df['CurrencyCode'] = currency_code\n",
    "    \n",
    "    # Append to the result DataFrame\n",
    "    result_df = pd.concat([result_df, merged_df])\n",
    "\n",
    "# Sort the result DataFrame by 'date'\n",
    "result_df.sort_values(by='Date', inplace=True)\n",
    "\n",
    "# Reset index\n",
    "result_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Replace commas with periods and convert to float\n",
    "result_df['ExchangeRate'] = result_df['ExchangeRate'].str.replace('.', '').str.replace(',', '.').astype(float)\n",
    "\n",
    "# Format ExchangeRate to 5 digits after the comma\n",
    "result_df['ExchangeRate'] = result_df['ExchangeRate'].map(lambda x: f\"{x:.4f}\")\n",
    "\n",
    "print(result_df.head(25))\n",
    "print(result_df.tail(25))\n",
    "result_df.to_csv('exchange_rates.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5691eec7-2bec-495a-af57-8e7af14707b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Fake accounting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a932ce2c-7c59-4649-ae61-db72843d1300",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Faker object\n",
    "faker = Faker()\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = pd.to_datetime('2023-01-01').timestamp()\n",
    "end_date = pd.to_datetime('2023-06-30').timestamp()\n",
    "\n",
    "# Generate 500,000 random dates between the start and end dates\n",
    "random_timestamps = np.random.randint(start_date, end_date, size=500000)\n",
    "random_dates = pd.to_datetime(random_timestamps, unit='s')\n",
    "\n",
    "# Generate 500,000 random figures between 0.01 and 150,000 and limit to 2 decimal places\n",
    "random_figures = np.round(np.random.uniform(0.01, 150000, size=500000), 2)\n",
    "\n",
    "# Generate 500,000 random text strings limited to 50 characters\n",
    "random_texts = [faker.text(max_nb_chars=50) for _ in range(500000)]\n",
    "\n",
    "# Generate 500,000 random currency codes from the provided list\n",
    "currency_codes = ['AUD', 'BGN', 'BRL', 'CAD', 'CHF', 'CNY', 'CZK', 'DKK', 'GBP', 'HKD', 'HUF', 'IDR', 'ILS', 'INR', 'ISK']\n",
    "random_currency_codes = np.random.choice(currency_codes, size=500000)\n",
    "\n",
    "# Generate 500,000 random account numbers between 00100 and 99999\n",
    "random_account_numbers = np.random.randint(100, 100000, size=500000)\n",
    "\n",
    "# Create a DataFrame with the specified column order\n",
    "df = pd.DataFrame({\n",
    "    'Date': random_dates,\n",
    "    'Text': random_texts,\n",
    "    'Account_Number': random_account_numbers,\n",
    "    'Amount': random_figures,\n",
    "    'CurrencyCode': random_currency_codes,\n",
    "})\n",
    "\n",
    "print(\"Shape of the DataFrame:\", df.shape)\n",
    "print(\"Head of the DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# df.to_csv('Accounting_Data.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "317c46d1-98fd-4ae0-8130-5f60588bc776",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Exchange rate calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "972e9606-acce-4b7e-a42a-9bf808fe090f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the existing DataFrame\n",
    "df = pd.read_csv('Accounting_Data.csv')\n",
    "\n",
    "# Load the exchange rates DataFrame\n",
    "exchange_rates = pd.read_csv('exchange_rates.csv', decimal='.', parse_dates=['Date'])\n",
    "\n",
    "# Convert the 'Date' column in the 'df' DataFrame to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Merge the DataFrames based on 'CurrencyCode' and 'Date', keeping all rows from 'df'\n",
    "merged_df = pd.merge(df, exchange_rates, how='left', on=['CurrencyCode', 'Date'])\n",
    "\n",
    "# Convert 'ExchangeRate' to float\n",
    "#merged_df['ExchangeRate'] = merged_df['ExchangeRate'].str.replace('.', '').str.replace(',', '.').astype(float)\n",
    "\n",
    "# Calculate 'Amount' in EUR\n",
    "merged_df['EUR_Amount'] = merged_df['Amount'] / merged_df['ExchangeRate']\n",
    "\n",
    "# Round 'EUR_Amount' column to 2 decimal places\n",
    "merged_df['EUR_Amount'] = merged_df['EUR_Amount'].round(2)\n",
    "\n",
    "# Reorder columns\n",
    "merged_df = merged_df[['Date', 'Text', 'Account_Number', 'Amount', 'CurrencyCode', 'EUR_Amount', 'ExchangeRate']]\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "merged_df.to_csv('Accounting_Data_with_EUR_final.csv', index=False)\n",
    "\n",
    "print(\"DataFrame with EUR amount rounded to 2 decimal places saved to 'Accounting_Data_with_EUR.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "264ae9ff-fbd0-4380-bd85-63ff7de0663b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "201b1749-69dd-434c-8f5f-cece47453938",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "250504-final_code_with_web_data1",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
